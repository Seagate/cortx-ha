#!/bin/bash

# Copyright (c) 2020 Seagate Technology LLC and/or its Affiliates
#
# This program is free software: you can redistribute it and/or modify it under the
# terms of the GNU Affero General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
# PARTICULAR PURPOSE. See the GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License along
# with this program. If not, see <https://www.gnu.org/licenses/>. For any questions
# about this software or licensing, please email opensource@seagate.com or
# cortx-questions@seagate.com.

HA_PATH="<HA_PATH>"
SOURCE_HA_CONF="<HA_PATH>/conf/etc"
HA_CONF="/etc/cortx/ha"
LOGROTATE_CONF="/etc/logrotate.d"
HA_LOG="/var/log/seagate/cortx/ha"

LOCAL_NODE_MINION_ID=$(salt-call grains.get id --output=json | jq '.["local"]' | sed s/\"//g)
SYSTEM_CROSS_CONNECT_FILE="/opt/seagate/cortx/provisioner/generated_configs/$LOCAL_NODE_MINION_ID.cc"

HA_NON_CROSS_CONNECT_RULE_FILE='rules_engine_schema_without_crossconnect.json'
HA_CROSS_CONNECT_RULE_FILE='rules_engine_schema_with_crossconnect.json'
HA_JBOD_RULE_FILE='rules_engine_schema_JBOD.json'
HA_VM_RULE_FILE='rules_engine_schema_single_vm.json'
HA_CONF_RULE_FILE='rules_engine_schema.json'

# Default Rule file will be VM Rule file
HA_RULE_FILE=$HA_VM_RULE_FILE

# username and password from prvsnrusers group to access Provisioner API
PRVSNR_USER=''
PRVSNR_PASSWORD=''
# Keys to be search from the API json op
BASE_KEY=".ret"
SERVER_TYPE_KEY=$BASE_KEY".server_type"
STORAGE_TYPE_KEY=$BASE_KEY".storage_type"


post_install() {
    echo "post_install"
    mkdir -p ${LOGROTATE_CONF}
    cp -rf ${HA_PATH}/conf/logrotate/cortx_ha_log.conf ${LOGROTATE_CONF}
}

detect_proper_rule_file() {

    case $1 in
        "5U84")
                echo "Physical server with: $1"
                HA_RULE_FILE=$( rule_file_for_5U84 )
                ;;
        "PODS")
                echo "Physical server with: $1"
                ;;
        "JBOD")
                echo "Physical server with: $1"
                HA_RULE_FILE=$HA_JBOD_RULE_FILE
                ;;
        *)
                echo "Physical server with: $1"
                echo -e "storage_type is not supported. Please recheck"
                echo "Assuming its a virtual Env"
                ;;
    esac

}

rule_file_for_5U84() {

    rule_file=${HA_CROSS_CONNECT_RULE_FILE}

    # Based on cross-connect check, load appropriate rule_engine
    # file. If cross-connect - load rules_engine_schema.json
    # If no cross-connect - load rules_engine_schema_without_crossconnect.json
    [[ -f ${SYSTEM_CROSS_CONNECT_FILE} ]] && echo "Cross connect File Exists" || {

        echo "Cross connect file does not exist"
        rule_file=${HA_NON_CROSS_CONNECT_RULE_FILE}
    }

    return $rule_file
}

config() {
    echo "config"

    # Get the setup information
    get_setup_info

    # Copy the appropriate Rules file
    cp -rf ${SOURCE_HA_CONF}/${HA_RULE_FILE} ${HA_CONF}/${HA_CONF_RULE_FILE}

    # Configure database.json
    config_database

    # Decision Maker conf
    config_decision_maker
}

get_setup_info() {
    # Provisioner API call to get system information
    system_json_op=`provisioner get_setup_info --username $PRVSNR_USER --password $PRVSNR_PASSWORD --output json`
    # output for above will be like:
    # {
    # "ret": {
    #     "nodes": 1,
    #     "server_type": "virtual",
    #     "servers_per_node": 2,
    #     "storage_type": "5u84"
    #     }
    # }
    # values for server_type: <"physical" | "virtual">
    # vales for storage_type: <"5U84" | "PODS" | "JBOD">
    # NOTE: JBOD detection is not in place yet!!

    server_type="$(echo "$system_json_op" | jq "$server_type_key")"
    if [ $server_type != "virtual" ]
        then
            # If storage type is not "virtual", means its a physical server
            storage_type="$(echo "$system_json_op" | jq "$storage_type_key")"

            # Get the proper rule file for the storage
            detect_proper_rule_file $storage_type
    fi
}

init() {
    echo "init"
}

test() {
    echo "test"
}

reset() {
    echo "reset log"
    rm -rf ${HA_LOG}
    rm -rf ${LOGROTATE_CONF}/cortx_ha_log.conf
    rm -rf ${HA_CONF}
}

replace_node() {
    # Test consul
    consul_host=$(cat /etc/cortx/ha/database.json | \
            jq '.databases.consul_db.config.host' | sed s/\"//g)
    consul_port=$(cat /etc/cortx/ha/database.json | \
            jq '.databases.consul_db.config.port' | sed s/\"//g)

    echo "Test consul leader for host: $consul_host port: $consul_port"
    curl http://$consul_host:$consul_port/v1/status/leader
    [ $? -eq 0 ] || {
        echo "Consul is not running"; exit 1
    }

    node_list=$(salt-call --local pillar.get cluster:node_list --output=json)
    host1=$(echo $node_list | jq '.["local"][0]' | sed s/\"//g)
    host2=$(echo $node_list | jq '.["local"][1]' | sed s/\"//g)

    # Get Faluty node name
    if [ $LOCAL_NODE_MINION_ID == $host1 ]; then
        faulty_node=$host2
    else
        faulty_node=$host1
    fi

    echo "Detected Faulty node $faulty_node"
    /usr/bin/cortxha cleanup db --node $faulty_node
}

# Helping function

config_database() {
    # Config database.json
    cp -rf ${SOURCE_HA_CONF}/database.json ${HA_CONF}

    # Update consul vip
    CONSUL_HOST=$(salt-call pillar.get \
        cluster:$LOCAL_NODE_MINION_ID:network:data_nw:roaming_ip \
        --output=json | jq '.["local"]' | sed s/\"//g)
    sed -i -e "s|<CONSUL_HOST>|${CONSUL_HOST}|g" ${HA_CONF}/database.json
}

config_decision_maker() {
    echo "Setup Decision maker"
    node_list=$(salt-call --local pillar.get cluster:node_list --output=json)
    host1=$(echo $node_list | jq '.["local"][0]' | sed s/\"//g)
    host2=$(echo $node_list | jq '.["local"][1]' | sed s/\"//g)

    for node in $(echo $host1 $host2); do
        bool=$(salt-call --local pillar.get cluster:$node:is_primary --output=json | jq '.["local"]')
        if $bool; then
           primery=$node
        fi
    done

    uuid_list=$(ssh $primery "salt '*' grains.get node_id --output=json")
    uuid1=$(echo $uuid_list | jq '.["'$host1'"]' | sed -e s/\"//g -e s/null//g -e '/^\s*$/d')
    uuid2=$(echo $uuid_list | jq '.["'$host2'"]' | sed -e s/\"//g -e s/null//g -e '/^\s*$/d')

    echo "Reading cluster.sls"

    # Data Network
    node1_clusterip_nw=$(salt-call pillar.get cluster:$host1:network:data_nw:iface:0 --output=newline_values_only)
    node2_clusterip_nw=$(salt-call pillar.get cluster:$host2:network:data_nw:iface:0 --output=newline_values_only)
    node1_data_nw="[ \"${node1_clusterip_nw}\" ]"
    node2_data_nw="[ \"${node2_clusterip_nw}\" ]"

    # Managment network
    cluster=$(salt-call --local pillar.get cluster:$host1 --output=json)
    node1_mgmt_nw=$(echo $cluster | jq '.["local"].network["mgmt_nw"].iface')
    node2_mgmt_nw=$(echo $cluster | jq '.["local"].network["mgmt_nw"].iface')

    decision_monitor_conf=${SOURCE_HA_CONF}/decision_monitor_conf.json
    cp -rf $decision_monitor_conf /tmp/decision_monitor_conf.json

    sed -i -e "s|<LOCAL>|${LOCAL_NODE_MINION_ID}|g" \
        -e "s|<HOST1>|${host1}|g" \
        -e "s|<HOST2>|${host2}|g" \
        -e "s|<UUID1>|${uuid1}|g" \
        -e "s|<UUID2>|${uuid2}|g" /tmp/decision_monitor_conf.json

    sed -i -e "s|\"<N1_DATA_IFACE>\"|${node1_data_nw//$'\n'/}|g" \
        -e "s|\"<N1_MGMT_IFACE>\"|${node1_mgmt_nw//$'\n'/}|g" \
        -e "s|\"<N2_DATA_IFACE>\"|${node2_data_nw//$'\n'/}|g" \
        -e "s|\"<N2_MGMT_IFACE>\"|${node2_mgmt_nw//$'\n'/}|g" /tmp/decision_monitor_conf.json

    cp -rf /tmp/decision_monitor_conf.json /etc/cortx/ha/decision_monitor_conf.json
    rm -rf /tmp/decision_monitor_conf.json
}

ACTION=$1
# Call action
$ACTION
