#!/bin/bash

HA_PATH="<HA_PATH>"
SOURCE_HA_CONF="<HA_PATH>/conf/etc"
HA_CONF="/etc/cortx/ha"
LOGROTATE_CONF="/etc/logrotate.d"
HA_LOG="/var/log/seagate/cortx/ha"

LOCAL_NODE_MINION_ID=$(salt-call grains.get id --output=json | jq '.["local"]' | sed s/\"//g)
SYSTEM_CROSS_CONNECT_FILE="/opt/seagate/cortx/provisioner/generated_configs/$LOCAL_NODE_MINION_ID.cc"

HA_NON_CROSS_CONNECT_RULE_FILE='rules_engine_schema_without_crossconnect.json'
HA_CROSS_CONNECT_RULE_FILE='rules_engine_schema_with_crossconnect.json'
HA_CONF_RULE_FILE='rules_engine_schema.json'

post_install() {
    echo "post_install"
    mkdir -p ${LOGROTATE_CONF}
    cp -rf ${HA_PATH}/conf/logrotate/cortx_ha_log.conf ${LOGROTATE_CONF}
}

config() {
    echo "config"

    rule_file=${HA_CROSS_CONNECT_RULE_FILE}

    # Based on cross-connect check, load appropriate rule_engine
    # file. If cross-connect - load rules_engine_schema.json
    # If no cross-connect - load rules_engine_schema_without_crossconnect.json
    [[ -f ${SYSTEM_CROSS_CONNECT_FILE} ]] && echo "Cross connect File Exists" || {

        echo "Cross connect file does not exist"
        rule_file=${HA_NON_CROSS_CONNECT_RULE_FILE}
    }

    # Copy a relevant rule file to HA_CONF directory with name as
    # 'rules_engine_schema.json' as HA component search for this specific name
    cp -rf ${SOURCE_HA_CONF}/${rule_file} ${HA_CONF}/${HA_CONF_RULE_FILE}

    # Configure database.json
    config_database

    # Decision Maker conf
    config_decision_maker
}

init() {
    echo "init"
}

test() {
    echo "test"
}

reset() {
    echo "reset log"
    rm -rf ${HA_LOG}
    rm -rf ${LOGROTATE_CONF}/cortx_ha_log.conf
    rm -rf ${HA_CONF}
}

replace_node() {
    # Test consul
    consul_host=$(cat /etc/cortx/ha/database.json | \
            jq '.databases.consul_db.config.host' | sed s/\"//g)
    consul_port=$(cat /etc/cortx/ha/database.json | \
            jq '.databases.consul_db.config.port' | sed s/\"//g)

    echo "Test consul leader for host: $consul_host port: $consul_port"
    curl http://$consul_host:$consul_port/v1/status/leader
    [ $? -eq 0 ] || {
        echo "Consul is not running"; exit 1
    }

    node_list=$(salt-call --local pillar.get cluster:node_list --output=json)
    host1=$(echo $node_list | jq '.["local"][0]' | sed s/\"//g)
    host2=$(echo $node_list | jq '.["local"][1]' | sed s/\"//g)

    # Get Faluty node name
    if [ $LOCAL_NODE_MINION_ID == $host1 ]; then
        faulty_node=$host2
    else
        faulty_node=$host1
    fi

    echo "Detected Faulty node $faulty_node"
    /usr/bin/cortxha cleanup db --node $faulty_node
}

# Helping function

config_database() {
    # Config database.json
    cp -rf ${SOURCE_HA_CONF}/database.json ${HA_CONF}

    # Update consul vip
    CONSUL_HOST=$(salt-call pillar.get \
        cluster:$LOCAL_NODE_MINION_ID:network:data_nw:roaming_ip \
        --output=json | jq '.["local"]' | sed s/\"//g)
    sed -i -e "s|<CONSUL_HOST>|${CONSUL_HOST}|g" ${HA_CONF}/database.json
}

config_decision_maker() {
    echo "Setup Decision maker"
    node_list=$(salt-call --local pillar.get cluster:node_list --output=json)
    host1=$(echo $node_list | jq '.["local"][0]' | sed s/\"//g)
    host2=$(echo $node_list | jq '.["local"][1]' | sed s/\"//g)

    for node in $(echo $host1 $host2); do
        bool=$(salt-call --local pillar.get cluster:$node:is_primary --output=json | jq '.["local"]')
        if $bool; then
           primery=$node
        fi
    done

    uuid_list=$(ssh $primery "salt '*' grains.get node_id --output=json")
    uuid1=$(echo $uuid_list | jq '.["'$host1'"]' | sed -e s/\"//g -e s/null//g -e '/^\s*$/d')
    uuid2=$(echo $uuid_list | jq '.["'$host2'"]' | sed -e s/\"//g -e s/null//g -e '/^\s*$/d')

    echo "Reading cluster.sls"

    # Data Network
    node1_clusterip_nw=$(salt-call pillar.get cluster:$host1:network:data_nw:iface:0 --output=newline_values_only)
    node2_clusterip_nw=$(salt-call pillar.get cluster:$host2:network:data_nw:iface:0 --output=newline_values_only)
    node1_data_nw="[ $node1_clusterip_nw ]"
    node2_data_nw="[ $node2_clusterip_nw ]"

    # Managment network
    cluster=$(salt-call --local pillar.get cluster:$host1 --output=json)
    node1_mgmt_nw=$(echo $cluster | jq '.["local"].network["mgmt_nw"].iface')
    node2_mgmt_nw=$(echo $cluster | jq '.["local"].network["mgmt_nw"].iface')

    decision_monitor_conf=${SOURCE_HA_CONF}/decision_monitor_conf.json
    cp -rf $decision_monitor_conf /tmp/decision_monitor_conf.json

    sed -i -e "s|<LOCAL>|${LOCAL_NODE_MINION_ID}|g" \
        -e "s|<HOST1>|${host1}|g" \
        -e "s|<HOST2>|${host2}|g" \
        -e "s|<UUID1>|${uuid1}|g" \
        -e "s|<UUID2>|${uuid2}|g" /tmp/decision_monitor_conf.json

    sed -i -e "s|\"<N1_DATA_IFACE>\"|${node1_data_nw//$'\n'/}|g" \
        -e "s|\"<N1_MGMT_IFACE>\"|${node1_mgmt_nw//$'\n'/}|g" \
        -e "s|\"<N2_DATA_IFACE>\"|${node2_data_nw//$'\n'/}|g" \
        -e "s|\"<N2_MGMT_IFACE>\"|${node2_mgmt_nw//$'\n'/}|g" /tmp/decision_monitor_conf.json

    cp -rf /tmp/decision_monitor_conf.json /etc/cortx/ha/decision_monitor_conf.json
    rm -rf /tmp/decision_monitor_conf.json
}

ACTION=$1
# Call action
$ACTION
