#!/usr/bin/env bash

# Copyright (c) 2020 Seagate Technology LLC and/or its Affiliates
#
# This program is free software: you can redistribute it and/or modify it under the
# terms of the GNU Affero General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
# PARTICULAR PURPOSE. See the GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License along
# with this program. If not, see <https://www.gnu.org/licenses/>. For any questions
# about this software or licensing, please email opensource@seagate.com or
# cortx-questions@seagate.com.

set -eu -o pipefail
export PS4='+ [${BASH_SOURCE[0]##*/}:${LINENO}${FUNCNAME[0]:+:${FUNCNAME[0]}}] '
# set -x

PROG=${0##*/}

usage() {
    cat <<EOF
Usage: $PROG [OPTS] <CDF> [<params.yaml>]

Configures build-ha-hare by preparing the configuration files and
adding resources into the Pacemaker.

Here are some prerequisites/guidelines:

* Pacemaker should be started & configured with a
  clean (without resources) cluser. Check with 'pcs status'.

* Password-less ssh access between the nodes is required.

* The script should be run from the "left" node.

* Make sure the provided roaming IP addresses belong to
  the local sub-network and are not used by anyone else.

Mandatory parameters:
  --ip1 <addr>         1st roaming IP address
  --ip2 <addr>         2nd roaming IP address.
        <CDF>          Hare Cluster Description File

Optional parameters:
  -i, --interface <if>  Data network interface (when they are the same
                        on both nodes, default: eth1)
  --left-iface    <if>  Left node data nw interface (default: eth1)
  --right-iface   <if>  Right node data nw interface (default: eth1)
  --left-node     <n1>  Left  node hostname (default: pod-c1)
  --right-node    <n2>  Right node hostname (default: pod-c2)
  --left-volume   <lv>  Left  node /var/motr volume (default: /dev/sdb)
  --right-volume  <rv>  Right node /var/motr volume (default: /dev/sdc)
  --skip-mkfs           Don't mkfs /var/motr
  --net-type <tcp|o2ib> LNet network type (default: tcp)
  --cib-file      <cf>  Pacemaker configuration file
  --update              Preserve Consul and Motr state, reconfigure Pacemaker
                        only.
  --restore-conf        Restore configuration files from the backup copy on the
                        peer node.

Note: parameters can be specified either directly via cmd-line options
or via a yaml file, e.g.:

  ip1: <ip>
  ip2: <ip2>
  interface: <iface>
  left-iface: <iface>
  right-iface: <iface>
  left-node: <lnode>
  right-node: <rnode>
  left-volume: <lvolume>
  right-volume: <rvolume>
  skip-mkfs: true
  net-type: <tcp|o2ib>
EOF
}

TEMP=$(getopt --options h,i: \
              --longoptions help,ip1:,ip2:,interface:,left-iface:,right-iface: \
              --longoptions left-node:,right-node: \
              --longoptions left-volume:,right-volume:,skip-mkfs,net-type: \
              --longoptions cib-file:,restore-conf,update \
              --name "$PROG" -- "$@" || true)

(($? == 0)) || { usage >&2; exit 1; }

eval set -- "$TEMP"

ip1=
ip2=
iface=eth1
left_iface=
right_iface=
lnode=pod-c1
rnode=pod-c2
lvolume=/dev/sdb
rvolume=/dev/sdc
skip_mkfs=false
net_type=tcp
update=false
restore_conf=false
cib_file=/var/lib/hare/cib_cortx_cluster.xml

while true; do
    case "$1" in
        -h|--help)           usage; exit ;;
        --ip1)               ip1=$2; shift 2 ;;
        --ip2)               ip2=$2; shift 2 ;;
        -i|--interface)      iface=$2; shift 2 ;;
        --left-iface)        left_iface=$2; shift 2 ;;
        --right-iface)       right_iface=$2; shift 2 ;;
        --left-node)         lnode=$2; shift 2 ;;
        --right-node)        rnode=$2; shift 2 ;;
        --left-volume)       lvolume=$2; shift 2 ;;
        --right-volume)      rvolume=$2; shift 2 ;;
        --skip-mkfs)         skip_mkfs=true; shift 1 ;;
        --net-type)          net_type=$2; shift 2 ;;
        --cib-file)          cib_file=$2; shift 2 ;;
        --update)            update=true; shift 2 ;;
        --restore-conf)      restore_conf=true; shift 2 ;;
        --)                  shift; break ;;
        *)                   break ;;
    esac
done

cdf=${1:-}
argsfile=${2:-}

hare_dir=/var/lib/hare
log_file=${LOG_FILE:-/var/log/build-ha.log}

die() {
    echo "$PROG: ERROR: $*" >&2
    exit 1
}

if [[ -f $argsfile ]]; then
    while IFS=': ' read name value; do
       case $name in
           ip1)          ip1=$value     ;;
           ip2)          ip2=$value     ;;
           interface)    iface=$value   ;;
           left-iface)   left_iface=$value   ;;
           right-iface)  right_iface=$value   ;;
           left-node)    lnode=$value   ;;
           right-node)   rnode=$value   ;;
           left-volume)  lvolume=$value ;;
           right-volume) rvolume=$value ;;
           skip-mkfs)
               [[ $value == true || $value == false ]] ||
                   die 'Invalid value of `skip-mkfs` parameter.
Supported values: true, false'
               skip_mkfs=$value ;;
           net-type)     net_type=$value ;;
           '')           ;;
           *) echo "Invalid parameter '$name' in $argsfile" >&2
              usage >&2; exit 1 ;;
       esac
    done < $argsfile
fi

# Set left/right_iface if they are not set explicitly by user:
[[ $left_iface ]] || left_iface=$iface
[[ $right_iface ]] || right_iface=$iface

[[ $ip1 ]] && [[ $ip2 ]] && [[ $cdf ]]  || {
    usage >&2
    exit 1
}

[[ -b $lvolume ]] || die "meta-data volume $lvolume is not available"
[[ -b $rvolume ]] || die "meta-data volume $rvolume is not available"

# Sample output:
#   $ ip -oneline -4 address show dev eno1
#   2: eno1    inet 10.230.249.241/20 brd 10.230.255.255 scope global noprefixroute dynamic eno1
#       valid_lft 327971sec preferred_lft 327971sec
#   2: eno1    inet 10.230.255.1/24 brd 10.230.255.255 scope global eno1:v1
#       valid_lft forever preferred_lft forever

# Check the netmask on the nodes - they must be the same.
netmaskl=$(ip -oneline -4 address show dev $left_iface | head -1 |
              awk '{print $4}' | cut -d/ -f2)
netmaskr=$(ssh $rnode ip -oneline -4 address show dev $right_iface | head -1 |
              awk '{print $4}' | cut -d/ -f2)
[[ $netmaskl == $netmaskr ]] ||
    die "Data network interfaces netmask differs between the nodes."
netmask=$netmaskl

run_on_both() {
    local cmd=$*
    eval $cmd
    ssh $rnode $cmd
}

log() {
    local msg=$1
    echo $msg >> $log_file
}

ip_addr_rsc_add() {
    log "${FUNCNAME[0]}: Adding the roaming IP addresses into Pacemaker..."
    sudo pcs -f $cib_file resource create ip-c1 ocf:heartbeat:IPaddr2 \
             ip=$ip1 cidr_netmask=$netmask iflabel=c1 op monitor interval=0
    sudo pcs -f $cib_file resource create ip-c2 ocf:heartbeat:IPaddr2 \
             ip=$ip2 cidr_netmask=$netmask iflabel=c2 op monitor interval=0
    sudo pcs -f $cib_file constraint location ip-c1 prefers $lnode
    sudo pcs -f $cib_file constraint location ip-c2 prefers $rnode
}

lnet_rsc_add() {
    log "${FUNCNAME[0]}: Adding LNet to pacemaker..."
    sudo pcs -f $cib_file resource create lnet systemd:lnet
    sudo pcs -f $cib_file resource clone lnet
    sudo pcs -f $cib_file resource create lnet-c1 ocf:cortx:lnet \
             ip=$ip1 nettype=$net_type op monitor interval=30s
    sudo pcs -f $cib_file resource create lnet-c2 ocf:cortx:lnet \
             ip=$ip2 nettype=$net_type op monitor interval=30s
    sudo pcs -f $cib_file resource group add c1 ip-c1 lnet-c1
    sudo pcs -f $cib_file resource group add c2 ip-c2 lnet-c2
    sudo pcs -f $cib_file constraint order lnet-clone then lnet-c1
    sudo pcs -f $cib_file constraint order lnet-clone then lnet-c2
}

net_config_check() {
    # Give Pacemaker time to configure the IPs
    for i in {1..10}; do
        sleep 5
        sudo lctl list_nids | grep -qF $ip1 || continue
        ssh $rnode "sudo lctl list_nids | grep -qF $ip2" || continue
        break
    done

    # Check the IPs
    check_msg="
    Check the following:
     1) Make sure the netmask of the main IP on data interface is <= 24 bits.
     2) Run 'pcs status' and make sure LNet is configured.
     3) STONITH is configured or disabled in Pacemaker."

    ip a | grep -qF $ip1 ||
      die "IP address $ip1 doesn't appear to be configured at $lnode. $check_msg"

    ssh $rnode "ip a | grep -qF $ip2" ||
      die "IP address $ip2 doesn't appear to be configured at $rnode. $check_msg"

    sudo lctl list_nids | grep -qF $ip1 ||
      die "LNet endpoint $ip1 doesn't appear to be configured at $lnode. $check_msg"

    ssh $rnode "sudo lctl list_nids | grep -qF $ip2" ||
      die "LNet endpoint $ip2 doesn't appear to be configured at $rnode. $check_msg"
}

# On both nodes:
# lvolume is mounted at /var/motr1,
# rvolume is mounted at /var/motr2.
prepare_var_motr_dirs() {
    log "${FUNCNAME[0]}: make sure there are no stale mounts hanging..."
    ssh $lnode 'mountpoint -q /var/motr1 && sudo umount /var/motr1 || true'
    ssh $rnode 'mountpoint -q /var/motr2 && sudo umount /var/motr2 || true'

    log "${FUNCNAME[0]}: check & upgrade old setups with /var/motr directories..."
    ssh $lnode '[ -d /var/motr ] && ! [ -d /var/motr1 ] && mv /var/motr /var/motr1 || true'
    ssh $rnode '[ -d /var/motr ] && ! [ -d /var/motr2 ] && mv /var/motr /var/motr2 || true'

    log "${FUNCNAME[0]}: prepare dirs..."
    run_on_both 'mkdir -p /var/motr{1,2}'
    ssh $lnode 'ln -sf /var/motr1 /var/motr'
    ssh $rnode 'ln -sf /var/motr2 /var/motr'

    ssh $lnode "sudo mount $lvolume /var/motr1 || true"
    ssh $rnode "sudo mount $rvolume /var/motr2 || true"
}

bootstrap() {
    if ! $skip_mkfs; then
        sudo mkfs.ext4 -q $lvolume >/dev/null <<< y
        sudo mkfs.ext4 -q $rvolume >/dev/null <<< y
    fi

    log "${FUNCNAME[0]}: Preparing Hare configuration files..."

# Update data_iface values in CDF: 1st data_iface will be `${left_iface}_c1`,
#                                  2nd data_iface will be `${right_iface}_c2`.
    sudo sed -r -e "/[#].*data_iface/b ; # skip commented out data_iface lines
                    /data_iface: *[a-z0-9]+[_:]c[12]/b ; # skip already updated
                    0,/(data_iface: *)[a-z0-9]+\b/s//\1${left_iface}_c1/ ;
                    0,/(data_iface: *)[a-z0-9]+\b/s//\1${right_iface}_c2/" \
                -i $cdf

    if facter --version | grep -q ^3; then
        # New facter-3 requires colons (:) for interface aliases.
        sudo sed -r -e "/[#].*data_iface/b ; # skip commented out data_iface lines
                        s/(data_iface: *(${left_iface}|${right_iface}))_(c[12])/\1:\3/" \
                    -i $cdf
    fi

# Make sure motr-kernel is not loaded.
    run_on_both 'sudo systemctl stop motr-kernel'

    hctl bootstrap --mkfs $cdf
    hctl shutdown

# LNet endpoints suffixes should be unique so that in case
# of a failover all the Motr services (which would work on
# the same node) could talk to each other.
# (It is a workaround for Motr EOS-2799 issue.)
    for f in $hare_dir/{confd.xc,consul-kv.json}; do
        sed -r -e "s/($ip2.*:12345:1):1/\1:2/" \
               -e "s/($ip2.*:12345:2):1/\1:3/" \
               -e "s/($ip2.*:12345:2):2/\1:4/" \
            -i $f
    done

    run_on_both 'sudo rm -f /etc/sysconfig/m0d-*'
    run_on_both 'sudo systemctl reset-failed hare\* m0d\*'
    hctl bootstrap --conf-dir $hare_dir
    hctl shutdown
}

# Runs hctl bootstrap to update hare configuration changes.
# Note: This modifies consul kv which needs to be explicitly restored.
bootstrap_update_only() {
    hctl bootstrap --conf-dir $hare_dir
    hctl shutdown
}

motr_config() {
    # Prepare Motr conf files on each node:
    lm0confs=$(echo /etc/sysconfig/m0d-*)
    rm0confs=$(sudo ssh $rnode 'echo /etc/sysconfig/m0d-*')
    sudo scp -q $lm0confs $rnode:/etc/sysconfig/
    sudo scp -q $rnode:\{${rm0confs/ /,}\} /etc/sysconfig/
    for f in $rm0confs; do sudo sed '1iMOTR_M0D_DATA_DIR=/var/motr2' -i $f; done
    ssh $rnode "for f in $lm0confs; do \
                           sudo sed '1iMOTR_M0D_DATA_DIR=/var/motr1' -i \$f; done"
}

cmd_deregister_node() {
    local node=$1
    cat <<EOF
/usr/bin/curl -i -X PUT -d '{\\"Node\\":\\"$node\\"}' \
    http://localhost:8500/v1/catalog/deregister
EOF
}

consul_systemd_prepare() {
    log "${FUNCNAME[0]}: Installing Consul systemd units..."
    cmd='
    sudo cp /usr/lib/systemd/system/hare-consul-agent.service
            /usr/lib/systemd/system/hare-consul-agent-c1.service &&
    sudo cp /usr/lib/systemd/system/hare-consul-agent.service
            /usr/lib/systemd/system/hare-consul-agent-c2.service &&
    for i in c{1,2}; do
        sudo sed "s/consul-env/&-$i/"
                 -i /usr/lib/systemd/system/hare-consul-agent-$i.service &&
        sudo sed "/ExecStart=/aExecStartPost=/bin/sleep 5"
                 -i /usr/lib/systemd/system/hare-consul-agent-$i.service;
    done'
    run_on_both $cmd
}

consul_systemd_update() {
    log "${FUNCNAME[0]}: Updating Consul systemd units..."
# Cleanup Consul data directory before starting the agent to
# avoid possible inconsistencies related to consensus when Consul
# agent joins the Consul cluster. Mainly problems related to leader
# election.

    consul_c2_cfg_dir=$hare_dir/consul-$ip2
    consul_c1_cfg_dir=$hare_dir/consul-$ip1

    sudo sed \
     -e "/ExecStart=/iExecStartPre=/bin/rm -rf $consul_c2_cfg_dir" \
     -i /usr/lib/systemd/system/hare-consul-agent-c2.service
    sudo systemctl daemon-reload

    cmd="
    sudo sed
     -e '/ExecStart=/iExecStartPre=/bin/rm -rf $consul_c1_cfg_dir'
     -i /usr/lib/systemd/system/hare-consul-agent-c1.service &&
    sudo systemctl daemon-reload"
    ssh $rnode $cmd

# Add and update node attribute for consul resource on both the nodes.
# This will be used to define constraints for the resources depending
# on consul.
   sudo sed \
    -e '/ExecStart=/aExecStartPost=/usr/sbin/attrd_updater -U 1 -n consul-c1-running' \
    -e '/ExecStartPost=/aExecStopPost=/usr/sbin/attrd_updater -U 0 -n consul-c1-running' \
    -i /usr/lib/systemd/system/hare-consul-agent-c1.service
   sudo systemctl daemon-reload

   cmd="
   sudo sed
    -e '/ExecStart=/aExecStartPost=/usr/sbin/attrd_updater -U 1 -n consul-c2-running' \
    -e '/ExecStartPost=/aExecStopPost=/usr/sbin/attrd_updater -U 0 -n consul-c2-running' \
    -i /usr/lib/systemd/system/hare-consul-agent-c2.service &&
   sudo systemctl daemon-reload"
   ssh $rnode $cmd

   unset consul_c1_cfg_dir consul_c2_cfg_dir
}

# Prepare consul-env-c{1,2} for the nodes. consul-env files (created by Hare)
# are used as a base. Few notes:
# 1) Only one consul-agent on the node can listen on 127.0.0.1
# address for the client requests, it will be consul-agent-c1 on node1 and
# consul-agent-c2 on node2 (hosting agent on each node).
# 2) `-retry-join $ip2` is added to consul-env-c1 so that during the failover
# or failback of node1 consul-agent-c1 could re-join with its peer on node2.
# 3) MODE is updated from `server` to `server-c{1,2}` so that each agent
# may have its own `-config-dir` at /var/lib/hare (refer to
# systemd/hare-consul startup script in Hare repo).
consul_env_prepare() {
    log "${FUNCNAME[0]}: Creating Consul environment..."
    sudo cp $hare_dir/consul-env $hare_dir/consul-env-c1
    scp $rnode:$hare_dir/consul-env $hare_dir/consul-env-c2
    sudo sed -r \
     -e 's/server$/server-c1/' \
     -e "s/JOIN=/&-retry-join $ip2 /" \
     -i $hare_dir/consul-env-c1
    sudo sed -r \
     -e 's/server$/server-c2/' \
     -e 's/127.0.0.1 //' \
     -i $hare_dir/consul-env-c2

    scp $hare_dir/consul-env $rnode:$hare_dir/consul-env-c1
    cmd="
    sudo cp $hare_dir/consul-env $hare_dir/consul-env-c2 &&
    sudo sed -r \
     -e 's/server$/server-c1/' \
     -e 's/127.0.0.1 //' \
     -e 's/JOIN=/&-retry-join $ip2 /' \
     -e 's/ -bootstrap-expect 1//' \
     -i $hare_dir/consul-env-c1 &&
    sudo sed -r \
     -e 's/server$/server-c2/' \
     -i $hare_dir/consul-env-c2"
    ssh $rnode $cmd
}

consul_conf_prepare() {
    log "${FUNCNAME[0]}: Preparing Consul agent configuration files..."
    run_on_both "mkdir -p $hare_dir/consul-server-c{1,2}-conf"

    conf_dir=consul-server-c1-conf

    sudo cp $hare_dir/consul-server-conf/consul-server-conf.json \
            $hare_dir/$conf_dir/$conf_dir.json
    sudo sed -e 's/"--hax"/"--svc", "hare-hax-c1"/' \
             -i $hare_dir/$conf_dir/$conf_dir.json

    cp $hare_dir/$conf_dir/$conf_dir.json /tmp/$conf_dir.json
    sudo sed -e '/\"server\"/a\ \ "leave_on_terminate": true,' \
             -i /tmp/$conf_dir.json
    scp /tmp/$conf_dir.json $rnode:$hare_dir/$conf_dir/
    rm /tmp/$conf_dir.json

    conf_dir=consul-server-c2-conf

    cmd="
    sudo cp $hare_dir/consul-server-conf/consul-server-conf.json \
            $hare_dir/$conf_dir/$conf_dir.json &&
    sudo sed -e 's/\"--hax\"/\"--svc\", \"hare-hax-c2\"/' \
             -i $hare_dir/$conf_dir/$conf_dir.json &&

    cp $hare_dir/$conf_dir/$conf_dir.json /tmp/$conf_dir.json &&
    sudo sed -e '/\"server\"/a\ \ \"leave_on_terminate\": true,' \
             -i /tmp/$conf_dir.json"

    ssh $rnode $cmd
    scp $rnode:/tmp/$conf_dir.json $hare_dir/$conf_dir/
    ssh $rnode "rm /tmp/$conf_dir.json"

    unset conf_dir
}

# Required in case of node replacement.
node_backup() {
    from=$1
    to=$2

    ssh $to "sudo mkdir -p /var/lib/hare/$from"
    ssh $to "sudo mkdir -p /etc/sysconfig/$from"

    sudo scp -r "$from:/var/lib/hare/consul-*" $to:/var/lib/hare/$from
    sudo scp $from:/var/lib/hare/node-name $to:/var/lib/hare/$from
    sudo scp "$from:/var/lib/hare/hax-env-*" $to:/var/lib/hare/$from
    sudo scp "$from:/etc/sysconfig/m0d-*" $to:/etc/sysconfig/$from
    sudo scp "$from:/etc/sysconfig/s3server-*" $to:/etc/sysconfig/$from
}

conf_backup() {
    node_backup $lnode $rnode
    node_backup $rnode $lnode
}

# Required in case of node replacement.
node_restore() {
    from=$1
    to=$2

    if ssh $from "[ -d /var/lib/hare/$to ]"; then
        ssh $to "sudo mkdir -p /var/lib/hare"
        # Restore files on lnode from rnode
        sudo scp -r "$from:/var/lib/hare/$to/consul-*" $to:/var/lib/hare/
        sudo scp "$from:/var/lib/hare/$to/node-name" $to:/var/lib/hare/
        sudo scp "$from:/var/lib/hare/$to/hax-env-*" $to:/var/lib/hare/
        sudo scp "$from:/etc/sysconfig/$to/m0d-*" $to:/etc/sysconfig/
        sudo scp "$from:/etc/sysconfig/$to/s3server-*" $to:/etc/sysconfig/
    fi
}

conf_restore() {
    node_restore $lnode $rnode
    node_restore $rnode $lnode

   # Backup from each node on each node again.
   conf_backup
}

consul_rsc_add() {
    log "${FUNCNAME[0]}: Adding Consul to Pacemaker..."
    sudo pcs -f $cib_file resource create consul-c1 systemd:hare-consul-agent-c1
    sudo pcs -f $cib_file resource create consul-c2 systemd:hare-consul-agent-c2
    sudo pcs -f $cib_file resource group add c1 consul-c1 --after ip-c1
    sudo pcs -f $cib_file resource group add c2 consul-c2 --after ip-c2
}

motr_kernel_rsc_add() {
    log "${FUNCNAME[0]}: Adding Motr kernel module to Pacemaker..."
    sudo pcs -f $cib_file resource create motr-kernel systemd:motr-kernel clone
    sudo pcs -f $cib_file constraint order lnet-c1 then motr-kernel-clone
    sudo pcs -f $cib_file constraint order lnet-c2 then motr-kernel-clone

    # Make sure motr-kernel is always stopped before lnet-c1/2
    # is started. Otherwise, some transition abort in between may
    # prevent motr-kernel restart. This is a workaround suggested
    # at https://bugs.clusterlabs.org/show_bug.cgi?id=5428#c5.
    sudo pcs -f $cib_file constraint order stop motr-kernel-clone then \
                                           start lnet-c1 \
                                           kind=Optional symmetrical=false
    sudo pcs -f $cib_file constraint order stop motr-kernel-clone then \
                                           start lnet-c2 \
                                           kind=Optional symmetrical=false
}

var_motr_rsc_add() {
    log "${FUNCNAME[0]}: Adding var-motr mounts to Pacemaker..."
    sudo pcs -f $cib_file resource create var-motr1 ocf:heartbeat:Filesystem \
        device=$lvolume directory=/var/motr1 \
        fstype=ext4 --group c1 op stop timeout=30
    sudo pcs -f $cib_file resource create var-motr2 ocf:heartbeat:Filesystem \
        device=$rvolume directory=/var/motr2 \
        fstype=ext4 --group c2 op stop timeout=30
}

hax_systemd_prepare() {
    log "${FUNCNAME[0]}: Installing hax systemd units..."
    sudo cp -f /usr/lib/systemd/system/hare-hax.service \
            /usr/lib/systemd/system/hare-hax-c1.service
    sudo cp -f /usr/lib/systemd/system/hare-hax.service \
            /usr/lib/systemd/system/hare-hax-c2.service
}

hax_systemd_update() {
    log "${FUNCNAME[0]}: Updating hax systemd units..."
    sudo sed -e 's/hare-consul-agent.service/hare-consul-agent-c1.service/' \
             -e "/ExecStart=/aTimeoutStopSec=5sec" \
             -e "/ExecStart=/aExecStopPost=/usr/sbin/attrd_updater -U 0 -n hax-running" \
             -e "/ExecStart=/aExecStartPost=/usr/sbin/attrd_updater -U 1 -n hax-running" \
             -i /usr/lib/systemd/system/hare-hax-c1.service
    sudo sed -e 's/hare-consul-agent.service/hare-consul-agent-c2.service/' \
             -e 's;ExecStart.*cd /var/motr;&2;' \
             -e "/ExecStart/iEnvironmentFile=$hare_dir/hax-env-c2" \
             -e "/ExecStart=/aTimeoutStopSec=5sec" \
             -e "/ExecStart=/aExecStopPost=/usr/sbin/attrd_updater -U 0 -n hax-running" \
             -e "/ExecStart=/aExecStartPost=/usr/sbin/attrd_updater -U 1 -n hax-running" \
             -i /usr/lib/systemd/system/hare-hax-c2.service
    echo "HARE_HAX_NODE_NAME=$rnode" | sudo tee $hare_dir/hax-env-c2 > /dev/null

    cmd="
    sudo cp -f /usr/lib/systemd/system/hare-hax.service
            /usr/lib/systemd/system/hare-hax-c1.service &&
    sudo sed -e 's/hare-consul-agent.service/hare-consul-agent-c1.service/'
             -e 's;ExecStart.*cd /var/motr;&1;' \
             -e '/ExecStart/iEnvironmentFile=$hare_dir/hax-env-c1'
             -e \"/ExecStart=/aTimeoutStopSec=5sec\"
             -e \"/ExecStart=/aExecStopPost=/usr/sbin/attrd_updater -U 0 -n hax-running\"
             -e \"/ExecStart=/aExecStartPost=/usr/sbin/attrd_updater -U 1 -n hax-running\"
             -i /usr/lib/systemd/system/hare-hax-c1.service &&
    sudo cp -f /usr/lib/systemd/system/hare-hax.service
            /usr/lib/systemd/system/hare-hax-c2.service &&
    sudo sed -e 's/hare-consul-agent.service/hare-consul-agent-c2.service/'
             -e \"/ExecStart=/aTimeoutStopSec=5sec\"
             -e \"/ExecStart=/aExecStopPost=/usr/sbin/attrd_updater -U 0 -n hax-running\"
             -e \"/ExecStart=/aExecStartPost=/usr/sbin/attrd_updater -U 1 -n hax-running\"
             -i /usr/lib/systemd/system/hare-hax-c2.service &&
    echo 'HARE_HAX_NODE_NAME=$lnode' | sudo tee $hare_dir/hax-env-c1 > /dev/null"
    ssh $rnode $cmd
}

hax_rsc_add() {
    log "${FUNCNAME[0]}: Adding hax to Pacemaker..."
    sudo pcs -f $cib_file resource create hax-c1 systemd:hare-hax-c1
    sudo pcs -f $cib_file resource create hax-c2 systemd:hare-hax-c2
    sudo pcs -f $cib_file resource group add c1 hax-c1
    sudo pcs -f $cib_file resource group add c2 hax-c2
    sudo pcs -f $cib_file constraint order motr-kernel-clone then hax-c1
    sudo pcs -f $cib_file constraint order motr-kernel-clone then hax-c2
    sudo pcs -f $cib_file constraint order consul-c2 then hax-c1
    sudo pcs -f $cib_file constraint order consul-c1 then hax-c2
}

motr_systemd_update() {
    log "${FUNCNAME[0]}: Adding Motr to Pacemaker..."

    cmd='
    sudo sed "s/TimeoutStopSec=.*/TimeoutStopSec=5sec/"
        -i /usr/lib/systemd/system/m0d@.service &&
    sudo systemctl daemon-reload'
    run_on_both $cmd
}

get_fid() {
    local node=$1
    local svc=$2

    local conf_dir=consul-server-$node-conf

    jq -r '.services[] | "\(.name) \(.checks[].args[])"' \
       $hare_dir/$conf_dir/$conf_dir.json | awk "/$svc.0x/ {print \$2}"
}

motr_rsc_add() {
    c1_confd=$(get_fid c1 confd)
    c2_confd=$(get_fid c2 confd)
    c1_ios=$(get_fid c1 ios)
    c2_ios=$(get_fid c2 ios)

    log "${FUNCNAME[0]}: Adding Motr to Pacemaker..."
    sudo pcs -f $cib_file resource create motr-confd-c1 systemd:m0d@$c1_confd op stop \
         timeout=600
    sudo pcs -f $cib_file resource create motr-ios-c1 systemd:m0d@$c1_ios op stop \
         timeout=600
    sudo pcs -f $cib_file resource group add c1 motr-confd-c1
    sudo pcs -f $cib_file resource group add c1 motr-ios-c1
    sudo pcs -f $cib_file resource create motr-confd-c2 systemd:m0d@$c2_confd op stop \
         timeout=600
    sudo pcs -f $cib_file resource create motr-ios-c2 systemd:m0d@$c2_ios op stop \
         timeout=600
    sudo pcs -f $cib_file resource group add c2 motr-confd-c2
    sudo pcs -f $cib_file resource group add c2 motr-ios-c2
    sudo pcs -f $cib_file constraint order motr-confd-c1 then motr-ios-c2
    sudo pcs -f $cib_file constraint order motr-confd-c2 then motr-ios-c1

    sudo pcs -f $cib_file resource create motr-free-space-mon systemd:motr-free-space-monitor \
         op monitor interval=30s meta failure-timeout=300s
    sudo pcs -f $cib_file constraint order motr-ios-c1 then motr-free-space-mon
    sudo pcs -f $cib_file constraint order motr-ios-c2 then motr-free-space-mon
    sudo pcs -f $cib_file constraint colocation add motr-free-space-mon with motr-ios-c1 \
         score=1000
    sudo pcs -f $cib_file constraint colocation add motr-free-space-mon with motr-ios-c2 \
         score=1000
}

is_virtual() {
    which facter &>/dev/null || return 1  # assume physical if facter is missing
    [[ $(facter is_virtual) == true ]] && return 0 || return 1
}

clusterip_rsc_add() {
    if ! is_virtual; then
        log "${FUNCNAME[0]}: Adding ClusterIP constraints in Pacemaker..."
        sudo pcs -f $cib_file constraint order c1 then ClusterIP-clone
        sudo pcs -f $cib_file constraint order c2 then ClusterIP-clone
        # Make ClusterIP to run only on nodes where motr and S3 stack are
        # present. S3 stack shall follow the same constraint.
        sudo pcs -f $cib_file constraint location ClusterIP-clone rule \
            score=-INFINITY '#uname' eq $lnode and hax-running eq 0
        sudo pcs -f $cib_file constraint location ClusterIP-clone rule \
            score=-INFINITY '#uname' eq $rnode and hax-running eq 0
    fi
}

systemd_units_disable() {
    log "${FUNCNAME[0]}: Disabling systemd units..."
    units_to_disable=(
        elasticsearch
        haproxy
        rabbitmq-server
        statsd
        slapd
        s3authserver
    )

    for u in ${units_to_disable[@]}; do
        run_on_both "sudo systemctl stop $u && sudo systemctl disable $u" || true
    done
}

ldap_rsc_add() {
    log "${FUNCNAME[0]}: Adding ldap to Pacemaker..."
    sudo pcs -f $cib_file resource create ldap systemd:slapd clone op monitor interval=30s
}

s3auth_rsc_add() {
    log "${FUNCNAME[0]}: Adding s3authserver to Pacemaker..."
    sudo pcs -f $cib_file resource create s3auth systemd:s3authserver clone op \
        monitor interval=30
    sudo pcs -f $cib_file constraint order ldap-clone then s3auth-clone
    sudo pcs -f $cib_file constraint order motr-ios-c1 then s3auth-clone
    sudo pcs -f $cib_file constraint order motr-ios-c2 then s3auth-clone
    # Make s3auth resource to run only on nodes where motr and hax are present.
    # All s3server resources shall follow s3auth due to colocation constraint.
    sudo pcs -f $cib_file constraint location s3auth-clone rule score=-INFINITY '#uname' \
        eq $lnode and hax-running eq 0
    sudo pcs -f $cib_file constraint location s3auth-clone rule score=-INFINITY '#uname' \
        eq $rnode and hax-running eq 0
}

elastic_search_rsc_add() {
    log "${FUNCNAME[0]}: Adding elastic search to Pacemaker.."
    sudo pcs -f $cib_file resource create els-search systemd:elasticsearch clone op \
        monitor interval=30s
}

statsd_rsc_add() {
    log "${FUNCNAME[0]}: Adding statsd to Pacemaker..."
    sudo pcs -f $cib_file resource create statsd systemd:statsd clone op monitor interval=30s
    sudo pcs -f $cib_file constraint order els-search-clone then statsd-clone
}

haproxy_rsc_add() {
    log "${FUNCNAME[0]}: Adding haproxy to pacemaker..."
    sudo pcs -f $cib_file resource create haproxy-c1 systemd:haproxy op monitor interval=30s
    sudo pcs -f $cib_file resource create haproxy-c2 systemd:haproxy op monitor interval=30s
    sudo pcs -f $cib_file constraint location haproxy-c1 prefers $lnode=INFINITY
    sudo pcs -f $cib_file constraint location haproxy-c1 avoids $rnode=INFINITY
    sudo pcs -f $cib_file constraint location haproxy-c2 prefers $rnode=INFINITY
    sudo pcs -f $cib_file constraint location haproxy-c2 avoids $lnode=INFINITY
}

get_s3_svc() {
    local cfg=$1
    local svc=$2
    jq -r '.services[] | "\(.name) \(.checks[].args[])"' $cfg |
        awk "/$svc.s3server@/ {print \$2}"
}

rabbitmq_rsc_add() {
    log "${FUNCNAME[0]}: Adding rabbit-mq resources and constraints..."
    sudo pcs -f $cib_file resource create rabbitmq systemd:rabbitmq-server clone op \
        monitor interval=30s meta failure-timeout=20s
}

s3_systemd_update() {
# Add and update node attribute for s3backgroundconsumer resource on both the
# nodes. This will be used to define constraints for the resources depending
# on s3backgroundconsumer resource on a node.
    log "${FUNCNAME[0]}: Updating s3 systemd units..."
    cmd="
    sudo sed
     -e '/ExecStart=/aExecStartPost=/usr/sbin/attrd_updater -U 1 -n s3backcons-running' \
     -e '/ExecStop=/aExecStopPost=/usr/sbin/attrd_updater -U 0 -n s3backcons-running' \
     -i /usr/lib/systemd/system/s3backgroundconsumer.service &&
    sudo systemctl daemon-reload"
    run_on_both $cmd
    cmd='
    sudo sed "s/TimeoutStopSec=.*/TimeoutStopSec=7sec/"
             -i /usr/lib/systemd/system/s3server@.service &&
    sudo systemctl daemon-reload'
    run_on_both $cmd
}

s3back_rsc_add() {
    log "${FUNCNAME[0]}: Adding s3background services..."
    sudo pcs -f $cib_file resource create s3backcons-c1 \
                          systemd:s3backgroundconsumer meta failure-timeout=300s
    sudo pcs -f $cib_file resource create s3backcons-c2 \
                          systemd:s3backgroundconsumer meta failure-timeout=300s
    sudo pcs -f $cib_file constraint location s3backcons-c1 avoids $rnode=INFINITY
    sudo pcs -f $cib_file constraint location s3backcons-c2 avoids $lnode=INFINITY
    sudo pcs -f $cib_file constraint order rabbitmq-clone then s3backcons-c1
    sudo pcs -f $cib_file constraint order rabbitmq-clone then s3backcons-c2
    sudo pcs -f $cib_file resource create s3backprod systemd:s3backgroundproducer op \
        monitor interval=30s
    sudo pcs -f $cib_file constraint order rabbitmq-clone then s3backprod
    sudo pcs -f $cib_file constraint location s3backprod rule score=-INFINITY '#uname' \
        eq $lnode and s3backcons-running eq 0
    sudo pcs -f $cib_file constraint location s3backprod rule score=-INFINITY '#uname' \
        eq $rnode and s3backcons-running eq 0
    sudo pcs -f $cib_file constraint colocation add s3backprod with s3backcons-c1 \
        score=50000
    sudo pcs -f $cib_file constraint colocation add s3backprod with s3backcons-c2 \
        score=50000
}

s3servers_all=

_s3server_rsc_add() {
   local suffix=$1
   local node_local=$2
   local node_remote=$3
   local s3servers=

   local conf_dir=consul-server-$suffix-conf
   local s3server_fids=(
       $(get_s3_svc $hare_dir/$conf_dir/$conf_dir.json s3service)
   )
   ((${#s3server_fids[@]} == 0)) && return

   local count=1
   for i in ${s3server_fids[@]}; do
      sudo pcs -f $cib_file resource create s3server-$suffix-$count systemd:$i op \
          stop timeout=600
      sudo pcs -f $cib_file constraint location s3server-$suffix-$count \
          prefers $node_local=INFINITY
      sudo pcs -f $cib_file constraint location s3server-$suffix-$count \
          avoids $node_remote=INFINITY
      # Order constraint adds the startup dependency of s3server on s3authserver
      sudo pcs -f $cib_file constraint \
           order s3auth-clone then s3server-$suffix-$count
      # Colocation constraint will add a s3server's liveness dependency
      # on the local s3authserver
      sudo pcs -f $cib_file constraint colocation add s3server-$suffix-$count \
          with s3auth-clone score=INFINITY
      s3servers+=" s3server-$suffix-$count"
      s3servers_all+=" s3server-$suffix-$count"
      (( count++ ))
   done

   sudo pcs -f $cib_file constraint order set $s3servers require-all=false \
       sequential=false set s3backcons-$suffix
   sudo pcs -f $cib_file constraint order set $s3servers require-all=false \
       sequential=false set haproxy-$suffix
}

s3server_rsc_add() {
    log "${FUNCNAME[0]}: Adding S3server to Pacemaker..."
    _s3server_rsc_add c1 $lnode $rnode
    _s3server_rsc_add c2 $rnode $lnode

    sudo pcs -f $cib_file constraint order set $s3servers_all require-all=false \
        sequential=false set s3backprod
}

cib_init() {
   sudo pcs cluster cib $cib_file
}

cib_commit() {
    sudo pcs cluster cib-push $cib_file --config
}

# HA operations table.
# The order of the functions is important here - it defines the
# order of the resources added into the Pacemaker's groups.
ha_ops=(
    ip_addr_rsc_add
    lnet_rsc_add
    net_config_check
    prepare_var_motr_dirs
    bootstrap
    bootstrap_update_only
    motr_config
    consul_systemd_prepare
    consul_systemd_update
    consul_env_prepare
    consul_conf_prepare
    consul_rsc_add
    motr_kernel_rsc_add
    var_motr_rsc_add
    hax_systemd_prepare
    hax_systemd_update
    hax_rsc_add
    motr_systemd_update
    motr_rsc_add
    clusterip_rsc_add
    systemd_units_disable
    ldap_rsc_add
    s3auth_rsc_add
    elastic_search_rsc_add
    statsd_rsc_add
    haproxy_rsc_add
    rabbitmq_rsc_add
    s3_systemd_update
    s3back_rsc_add
    s3server_rsc_add
    conf_backup
    conf_restore
)

# Maps ha operation from the ha_ops table to its respective type.
# HA operations are classified and described as follows,
# bootstrap:   executes during clean installation of the software only
# update:      executes during clean install and software update
# update-only: executes during software update only
# restore:     executes typically in-order to restore the configuration files
declare -A ha_ops_type=(
    [ip_addr_rsc_add]='bootstrap_update'
    [lnet_rsc_add]='bootstrap_update'
    [net_config_check]='bootstrap'
    [prepare_var_motr_dirs]='bootstrap_update_restore'
    [bootstrap]='bootstrap'
    [bootstrap_update_only]='update-only'
    [motr_config]='bootstrap'
    [consul_systemd_prepare]='bootstrap_update_restore'
    [consul_systemd_update]='bootstrap_update_restore'
    [consul_env_prepare]='bootstrap'
    [consul_conf_prepare]='bootstrap'
    [consul_rsc_add]='bootstrap_update'
    [motr_kernel_rsc_add]='bootstrap_update'
    [var_motr_rsc_add]='bootstrap_update'
    [hax_systemd_prepare]='bootstrap_update_restore'
    [hax_systemd_update]='bootstrap_update_restore'
    [hax_rsc_add]='bootstrap_update'
    [motr_systemd_update]='bootstrap_update_restore'
    [motr_rsc_add]='bootstrap_update'
    [clusterip_rsc_add]='bootstrap_update'
    [systemd_units_disable]='bootstrap_update'
    [ldap_rsc_add]='bootstrap_update'
    [s3auth_rsc_add]='bootstrap_update'
    [elastic_search_rsc_add]='bootstrap_update'
    [statsd_rsc_add]='bootstrap_update'
    [haproxy_rsc_add]='bootstrap_update'
    [rabbitmq_rsc_add]='bootstrap_update'
    [s3_systemd_update]='bootstrap_update'
    [s3back_rsc_add]='bootstrap_update'
    [s3server_rsc_add]='bootstrap_update'
    [conf_backup]='bootstrap'
    [conf_restore]='restore'
)

for op in ${ha_ops[@]}; do
    if $restore_conf && [[ ${ha_ops_type[$op]} =~ .*'restore'.* ]]; then
        $op
    elif ! $update && ! $restore_conf && [[ ${ha_ops_type[$op]} =~ .*'bootstrap'.* ]]; then
        cib_init
        $op
        cib_commit
    elif $update && [[ ${ha_ops_type[$op]} =~ .*'update'.* ]]; then
        # We are using existing CIB as a base and re-applying the pcs
        # instructions, thus some instructions would already exist in the
        # CIB, we ignore them.
        $op || true
        cib_commit
    fi
done
